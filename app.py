import datetime
import secrets
import os
from os.path import join
from flask import Flask, render_template, request
import time
import pickle
import shutil
import pandas as pd
 

# create an instance of the Flask class, with the name of the running application and the paths for the static files and templates
app = Flask(__name__, static_folder='static', template_folder="templates")

# set the upload folder to the absolute path of the "upload_folder" directory
app.config['UPLOAD_FOLDER'] = os.path.abspath("upload_folder")

# set the lifetime of a session to one hour
app.config["PERMANENT_SESSION_LIFETIME"] = datetime.timedelta(hours=1)

# set the secret key to a random string generated by the secrets module
app.config["SECRET_KEY"] = secrets.token_hex()

##################### model pe ##################################
# Load the models_pe_tw once
models_names = ["lgbm_0.pkl", "lgbm_1.pkl", "lgbm_2.pkl"]
loaded_models = []
for model_name in models_names:
    with open(join("models_pe_tw", model_name), "rb") as file:
        model = pickle.load(file)
        loaded_models.append(model)
##################### model pe ##################################

##################### model gdm ##################################
# Load the GDM models once - fix the model loading
models_names_gdm = ["lgbm_0.pkl", "lgbm_1.pkl", "lgbm_2.pkl", "lgbm_3.pkl"]  # Added model_3
loaded_models_gdm = []
for model_name in models_names_gdm:
    try:
        with open(join("models_gdm", model_name), "rb") as file:
            model = pickle.load(file)
            loaded_models_gdm.append(model)
    except FileNotFoundError:
        print(f"Warning: GDM model {model_name} not found")
##################### model gdm ##################################

def divide_array(arr, num_subarrays):
    #divides array to a number of sub arrays
    n = len(arr)
    subarray_size = n // num_subarrays
    remainder = n % num_subarrays

    subarrays = []
    start_index = 0

    for i in range(num_subarrays):
        end_index = start_index + subarray_size + (1 if i < remainder else 0)
        subarrays.append(arr[start_index:end_index])
        start_index = end_index

    return subarrays


# Fixed calculate_risk function to handle both PE and GDM
def calculate_risk(predict_prob, step, model_type="pe"):
    list_pred = []
    list_pred_real = []

    # Choose the correct predictions file based on model type
    if model_type == "gdm":
        pred_file_path = f"predicted_results_gdm/GDM_{step}.csv"
    else:
        pred_file_path = f"predicted_results_pe_tw/predictions_with_label_{step}.csv"

    try:
        with open(pred_file_path) as pred_file:
            for line in pred_file:
                line = line.strip().split(',')
                list_pred.append(float(line[1]))
                list_pred_real.append([float(line[0]), float(line[1])])
    except FileNotFoundError:
        print(f"Warning: Prediction file {pred_file_path} not found")
        return predict_prob  # Return raw probability as fallback

    # sort list_pred_real by pred
    sorted_list_pred_real = sorted(list_pred_real, key=lambda x: x[1])

    sorted_list_pred_real[0][1] = 0
    sorted_list_pred_real[-1][1] = 1.0
    subarrays = 20
    bins_20 = divide_array(sorted_list_pred_real, subarrays)
    for bin in bins_20:
        if predict_prob < bin[-1][1]:
            vals = [val[0] for val in bin]
            risk = sum(vals) / len(vals)
            return risk

    return predict_prob  # Fallback


@app.route('/process_gdm_form', methods=['POST', 'GET'])
def process_gdm_form():
    try:
        # Get the form data
        data = request.form

        # Load mean values from CSV for GDM
        try:
            mean_std_df = pd.read_csv("./static/mean_std_gdm.csv")
        except FileNotFoundError:
            return render_template("gdm.html", active="GDM", risks=[],
                                   error="GDM model configuration file not found")

        mean_dict = dict(zip(mean_std_df["label"], mean_std_df["Mean"]))
        # Build the data dictionary with mean imputation
        data_dict = {}
        for label in mean_dict.keys():
            value = data.get(label)
            if value in [None, ""]:
                # print(f"[WARNING] Missing value for '{label}', using mean: {mean_dict.get(label, 0.0)}")
                data_dict[label] = mean_dict.get(label, 0.0)
            else:
                data_dict[label] = float(value)
                # print(f"Value for '{label}', using input: {data_dict[label]}")
        print("\n")

        # Build the DataFrame from the final dictionary
        data_df = pd.DataFrame({k: [v] for k, v in data_dict.items()})

        # Normalize the data (no need to normalize because GDM models are already trained with original data)

        # Predict the risk using GDM models
        risks = []
        model_from_step = [0, 1, 2, 3]  # Updated to match 4 models

        for i, model in enumerate(loaded_models_gdm):
            if i >= len(model_from_step):
                break

            data_df_ = data_df.copy()
            try:
                feature_names = model.feature_name()

                # Check if all required features are available
                missing_features = [f for f in feature_names if f not in data_df_.columns]
                if missing_features:
                    print(f"Warning: Missing features for model {i}: {missing_features}")
                    # Fill missing features with 0 or mean values
                    for feature in missing_features:
                        data_df_[feature] = 0.0

                data_df_ = data_df_[feature_names]
                probabilities = model.predict(data_df_)
                risk = probabilities[0]
                final_risk = calculate_risk(risk, model_from_step[i], "gdm")
                risks.append(final_risk)

            except Exception as e:
                print(f"Error with model {i}: {e}")
                risks.append(0.0)  # Fallback risk

        # Format output risks
        output_risks = [str(round(float(risk * 100), 2)) + '%' for risk in risks]

        return render_template("gdm.html", active="GDM", risks=output_risks)

    except Exception as e:
        print(f"Error in process_gdm_form: {e}")
        return render_template("gdm.html", active="GDM", risks=[], error=str(e))


@app.route('/process_pe_form', methods=['POST', 'GET'])
def process_pe_form():
    try:
        # Get the form data
        data = request.form

        # Load mean values from CSV
        mean_std_df = pd.read_csv("./static/mean_std_tw.csv")
        mean_dict = dict(zip(mean_std_df["label"], mean_std_df["Mean"]))

        # Start with the actual form data
        data_df = pd.DataFrame({key: [float(value)] for key, value in data.items() if value not in [None, ""]})

        # Print what we got from the form
        print("Form data received:", list(data_df.columns))

        # Add missing features with mean values
        for label in mean_dict.keys():
            if label not in data_df.columns:
                data_df[label] = [mean_dict[label]]

        with open(f"static/mean_std_tw.csv") as mean_std_f:
            for line in mean_std_f:
                if "label,Mean,Std" in line:# skip header
                    continue
                label, mean, std = line.strip().split(",")

                if label not in data_df.columns:
                    print(f"Skipping label '{label}' because it is not in the DataFrame.")
                    continue                
                # Skip columns where std is empty
                if not std.strip():
                    print(f"Skipping column '{label}' because std is empty.")
                    continue
                
                # Convert mean and std to floats
                mean = float(mean)
                std = float(std)
                

                # Apply normalization
                data_df[label] = (data_df[label] - mean) / std

        # Predict the risk
        risks = []
        model_from_trimester = [0,1,2]
        
        for i,model in enumerate(loaded_models):
            data_df_ = data_df.copy()
            feature_names = model.feature_name()
            data_df_ = data_df_[feature_names]  # Ensure the order of the columns is the same as when the model was trained
            probabilities = model.predict(data_df_)  # For binary classification, this returns probabilities for class 1
            risk = probabilities[0]  # Extract the probability for the first sample
            final_risk = calculate_risk(risk,model_from_trimester[i])
            risks.append(final_risk)

        output_risks = [str(round(float(risk*100), 2))+'%' for risk in risks]

        return render_template("index.html", active="Home", risks=output_risks) #Todo- Home??
    except Exception as e:
        return render_template("index.html", active="Home", risks=[], error=str(e))


@app.route('/', methods=['GET'])
@app.route('/Home', methods=['GET'])
def home():
    return render_template("home.html", active="Home", risks=None)


@app.route('/Example', methods=['GET'])
def example():
    return render_template("example.html", active="Example")


@app.route('/About', methods=['GET'])
def about():
    return render_template("about.html", active="About")

@app.route('/Glossary', methods=['GET'])
def glossary():
    return render_template("glossary.html", active="Glossary")

###############pe model###############
@app.route('/PE_Twins', methods=['GET'])
def pe_twins():
    return render_template("index.html", active="Glossary")
###############pe model###############

###############model gdm##############
@app.route('/GDM', methods=['GET'])
def gdm():
    return render_template("gdm.html", active="Glossary")
###############model gdm##############

if __name__ == "__main__":
    app.run(debug=True, host='0.0.0.0', port=5000, use_reloader=True)
