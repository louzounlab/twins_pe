import datetime
import secrets
import os
from os.path import join
from flask import Flask, render_template, request
import time
import pickle
import shutil
import pandas as pd


# create an instance of the Flask class, with the name of the running application and the paths for the static files and templates
app = Flask(__name__, static_folder='static', template_folder="templates")

# set the upload folder to the absolute path of the "upload_folder" directory
app.config['UPLOAD_FOLDER'] = os.path.abspath("upload_folder")

# set the lifetime of a session to one hour
app.config["PERMANENT_SESSION_LIFETIME"] = datetime.timedelta(hours=1)

# set the secret key to a random string generated by the secrets module
app.config["SECRET_KEY"] = secrets.token_hex()

# Load the models once
models_names = ["lgbm_0.pkl", "lgbm_1.pkl", "lgbm_2.pkl"]
loaded_models = []
for model_name in models_names:
    with open(join("models", model_name), "rb") as file:
        model = pickle.load(file)
        loaded_models.append(model)


def clean_old_files():
    files = os.listdir("static")
    for file in files:
        if os.path.isdir(join("static", file)) and file != "bootstrap":
            # Time is older than an hour
            if time.time() - float(file) > 3600:
                shutil.rmtree(join("static", file))
                print("Deleted:", file)

def divide_array(arr, num_subarrays):
    #divides array to a number of sub arrays
    n = len(arr)
    subarray_size = n // num_subarrays
    remainder = n % num_subarrays

    subarrays = []
    start_index = 0

    for i in range(num_subarrays):
        end_index = start_index + subarray_size + (1 if i < remainder else 0)
        subarrays.append(arr[start_index:end_index])
        start_index = end_index

    return subarrays


def calculate_risk(predict_prob,step):
    list_pred = []
    list_pred_real = []
    with open(f"predicted_results/predictions_with_label_{step}.csv") as pred_file:
        for line in pred_file:
            line = line.strip().split(',')
            list_pred.append(float(line[1]))
            list_pred_real.append([float(line[0]), float(line[1])])
    # sort list_pred_real by pred
    sorted_list_pred_real = sorted(list_pred_real, key=lambda x: x[1])
    # sorted_list_pred = sorted(list_pred)

    # percentile = find_percentile(predict_prob, np.array(sorted_list_pred))
    # print("percentile", percentile)
    sorted_list_pred_real[0][1] = 0
    sorted_list_pred_real[-1][1] = 1.1
    subarrays = 20
    bins_20 = divide_array(sorted_list_pred_real, subarrays)
    for bin in bins_20:
        if predict_prob<bin[-1][1] :
            vals = [val[0] for val in bin]
            risk = sum(vals) / len(vals)
            return risk
@app.route('/process_form', methods=['POST', 'GET'])
def process_form():
    try:
        # Get the form data
        data = request.form
        # data_df = pd.DataFrame({
        #     "Trim_1_cffDNA": [1.0 if data.get("Trim_1_cffDNA") == "on" else 0.0],
        #     "Trim_1_B": [1.0 if data.get("Trim_1_B") == "on" else 0.0],
        #     "DM": [1.0 if data.get("DM") == "on" else 0.0],
        #     "Nulliparous": [1.0 if data.get("Nulliparous") == "on" else 0.0],
        #     "Trim_1_MAP": [float(data["Trim_1_MAP"]) if data.get("Trim_1_MAP") else 85.0],
        #     "Trim_1_PLGF": [float(data["Trim_1_PLGF"]) if data.get("Trim_1_PLGF") else 150.0],
        # })

        data_df = pd.DataFrame({
            "Trim_1_cffDNA": [float(data.get("Trim_1_cffDNA")) if data.get("Trim_1_cffDNA") != "" else 14.34537],#
            "Trim_1_B": [float(data.get("Trim_1_B")) if data.get("Trim_1_B") != "" else 0.0],#
            "DM": [float(data.get("DM")) if data.get("DM") != "" else 0.0],#
            "Nulliparous": [float(data.get("Nulliparous")) if data.get("Nulliparous") != "" else 0.0],#
            "Trim_1_MAP": [float(data["Trim_1_MAP"]) if data.get("Trim_1_MAP") else 88.3879],
            "Trim_1_PLGF": [float(data["Trim_1_PLGF"]) if data.get("Trim_1_PLGF") else 0.00644],
            "Trim_2_MAP": [float(data["Trim_2_MAP"]) if data.get("Trim_2_MAP") else 85.61800],
            "Trim_2_SFLT1": [float(data["Trim_2_SFLT1"]) if data.get("Trim_2_SFLT1") else -0.01312],
            "Trim_2_sflt1/PlGf": [float(data["Trim_2_sflt1/PlGf"]) if data.get("Trim_2_sflt1/PlGf") else 7.40313],
            "Trim_2_PLGF": [float(data["Trim_2_PLGF"]) if data.get("Trim_2_PLGF") else 0.00150],
            "Trim_3_MAP": [float(data["Trim_3_MAP"]) if data.get("Trim_3_MAP") else 86.2462],
            "Trim_3_SFLT1/PLGF": [float(data["Trim_3_SFLT1/PLGF"]) if data.get("Trim_3_SFLT1/PLGF") else 24.65062],
            "Trim_3_SFLT1": [float(data["Trim_3_SFLT1"]) if data.get("Trim_3_SFLT1") else -0.00567],
            "Trim_3_PLGF": [float(data["Trim_3_PLGF"]) if data.get("Trim_3_PLGF") else 0.00023],
        })



        with open(f"static/mean_std_tw.csv") as mean_std_f:
            for line in mean_std_f:
                if "label,Mean,Std" in line:
                    continue
                label, mean, std = line.strip().split(",")

                if label not in data_df.columns:
                    print(f"Skipping label '{label}' because it is not in the DataFrame.")
                    continue                
                # Skip columns where std is empty
                if not std.strip():
                    print(f"Skipping column '{label}' because std is empty.")
                    continue
                
                # Convert mean and std to floats
                mean = float(mean)
                std = float(std)
                
                # Apply normalization
                data_df[label] = (data_df[label] - mean) / std
        # Predict the risk
        risks = []
        model_from_trimester = [0,1,2]
        
        for i,model in enumerate(loaded_models):
            data_df_ = data_df.copy()
            # risk = model.predict_proba(data_df)[:, 1][0]
            # Assuming `model` is a LightGBM Booster object
            feature_names = model.feature_name()
            print("Features the model learned about:", feature_names)
            data_df_ = data_df_[feature_names]  # Ensure the order of the columns is the same as when the model was trained
            probabilities = model.predict(data_df_)  # For binary classification, this returns probabilities for class 1
            risk = probabilities[0]  # Extract the probability for the first sample
            final_risk = calculate_risk(risk,model_from_trimester[i])
            risks.append(final_risk)
            #risks.append(risk)

        output_risks = [str(round(float(risk*100), 2))+'%' for risk in risks]

        return render_template("index.html", active="Home", risks=output_risks)
    except Exception as e:
        return render_template("index.html", active="Home", risks=[], error=str(e))


@app.route('/', methods=['GET'])
@app.route('/Home', methods=['GET'])
def home():
    return render_template("index.html", active="Home", risks=None)


@app.route('/Example', methods=['GET'])
def example():
    return render_template("example.html", active="Example")


@app.route('/About', methods=['GET'])
def about():
    return render_template("about.html", active="About")

@app.route('/Glossary', methods=['GET'])
def glossary():
    return render_template("glossary.html", active="Glossary")


if __name__ == "__main__":
    app.run(debug=True, host='0.0.0.0', port=5000, use_reloader=True)
